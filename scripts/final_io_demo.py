"""
æ•°æ®å¥åº·æ£€æŸ¥å™¨ - æœ€ç»ˆè¾“å…¥è¾“å‡ºæ¼”ç¤º
æ¸…æ™°å±•ç¤ºè¾“å…¥ä»€ä¹ˆæ•°æ®ï¼Œè¾“å‡ºä»€ä¹ˆç»“æœ
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta

from enhanced_data_health_checker import EnhancedDataHealthChecker
from data_cleaner import DataCleaner, CleaningConfig, CleaningMethod


def create_sample_data():
    """åˆ›å»ºç¤ºä¾‹æ•°æ®"""
    # åˆ›å»º30è¡Œçš„ç¤ºä¾‹è‚¡ç¥¨æ•°æ®
    dates = pd.date_range(start='2024-01-01 09:30:00', periods=30, freq='30min')
    
    # ç”Ÿæˆæ¨¡æ‹Ÿä»·æ ¼æ•°æ®
    np.random.seed(42)  # å›ºå®šéšæœºç§å­ç¡®ä¿ç»“æœä¸€è‡´
    base_price = 150.0
    price_changes = np.random.normal(0, 0.02, 30)
    prices = []
    current_price = base_price
    
    for change in price_changes:
        current_price *= (1 + change)
        prices.append(current_price)
    
    # åˆ›å»ºOHLCVæ•°æ®
    data = []
    for i, (date, price) in enumerate(zip(dates, prices)):
        high = price * (1 + abs(np.random.normal(0, 0.01)))
        low = price * (1 - abs(np.random.normal(0, 0.01)))
        open_price = prices[i-1] if i > 0 else price
        close_price = price
        volume = np.random.randint(100000, 1000000)
        
        data.append({
            'open': round(open_price, 2),
            'high': round(high, 2),
            'low': round(low, 2),
            'close': round(close_price, 2),
            'volume': volume
        })
    
    df = pd.DataFrame(data, index=dates)
    df.index.name = 'datetime'
    return df


def main_demo():
    """ä¸»è¦æ¼”ç¤º"""
    print("ğŸ§ª æ•°æ®å¥åº·æ£€æŸ¥å™¨ - è¾“å…¥è¾“å‡ºæ¼”ç¤º")
    print("=" * 70)
    
    # 1. åˆ›å»ºç¤ºä¾‹æ•°æ®
    print("\nğŸ“Š 1. è¾“å…¥æ•°æ®å±•ç¤º")
    print("-" * 50)
    df = create_sample_data()
    
    print("âœ… è¾“å…¥è¦æ±‚:")
    print("   - pandas DataFrame")
    print("   - åŒ…å« ['open', 'high', 'low', 'close', 'volume'] åˆ—")
    print("   - DatetimeIndex æ—¶é—´ç´¢å¼• (æ¨è)")
    print("   - æ•°å€¼å‹æ•°æ®")
    
    print(f"\nğŸ“¥ å®é™…è¾“å…¥:")
    print(f"   æ•°æ®ç±»å‹: {type(df)}")
    print(f"   æ•°æ®å½¢çŠ¶: {df.shape}")
    print(f"   åˆ—å: {list(df.columns)}")
    print(f"   æ—¶é—´èŒƒå›´: {df.index[0]} åˆ° {df.index[-1]}")
    print(f"   æ•°æ®ç±»å‹:\n{df.dtypes.to_string()}")
    
    print(f"\nğŸ“‹ æ•°æ®é¢„è§ˆ (å‰5è¡Œ):")
    print(df.head().to_string())
    
    # 2. æ¨¡æ‹Ÿæ•°æ®é—®é¢˜
    print(f"\nğŸ”§ 2. æ¨¡æ‹Ÿæ•°æ®é—®é¢˜")
    print("-" * 50)
    df_with_issues = df.copy()
    
    # æ·»åŠ å„ç§é—®é¢˜
    df_with_issues.iloc[5:8, 1] = np.nan  # ç¼ºå¤±å€¼
    df_with_issues.iloc[10, 3] = df_with_issues.iloc[10, 3] * 20  # å¼‚å¸¸å€¼
    df_with_issues.iloc[15, 4] = -1000  # è´Ÿæˆäº¤é‡
    df_with_issues.iloc[20, 0] = 0  # é›¶å¼€ç›˜ä»·
    
    print("æ·»åŠ çš„é—®é¢˜:")
    print("   â• ç¼ºå¤±å€¼: ç¬¬6-8è¡Œçš„highåˆ—")
    print("   â• å¼‚å¸¸å€¼: ç¬¬11è¡Œçš„closeä»·æ ¼ (20å€)")
    print("   â• è´Ÿæˆäº¤é‡: ç¬¬16è¡Œçš„volume")
    print("   â• é›¶å¼€ç›˜ä»·: ç¬¬21è¡Œçš„open")
    
    print(f"\nğŸ“Š é—®é¢˜ç»Ÿè®¡:")
    print(f"   ç¼ºå¤±å€¼æ€»æ•°: {df_with_issues.isnull().sum().sum()}")
    print(f"   è´Ÿå€¼æ•°é‡: {(df_with_issues < 0).sum().sum()}")
    print(f"   é›¶å€¼æ•°é‡: {(df_with_issues == 0).sum().sum()}")
    
    # 3. æ‰§è¡Œå¥åº·æ£€æŸ¥
    print(f"\nğŸ” 3. å¥åº·æ£€æŸ¥è¿‡ç¨‹")
    print("-" * 50)
    checker = EnhancedDataHealthChecker()
    
    print("æ‰§è¡Œæ­¥éª¤:")
    print("   1ï¸âƒ£ ç¼ºå¤±å€¼æ£€æŸ¥å’Œå¤„ç†")
    print("   2ï¸âƒ£ å¼‚å¸¸å€¼æ£€æµ‹å’Œå¤„ç†") 
    print("   3ï¸âƒ£ æ—¶é—´è¿ç»­æ€§éªŒè¯")
    print("   4ï¸âƒ£ æ•°æ®é¢‘ç‡ä¸€è‡´æ€§æ£€æŸ¥")
    print("   5ï¸âƒ£ ä»·æ ¼é€»è¾‘å…³ç³»éªŒè¯")
    print("   6ï¸âƒ£ æˆäº¤é‡å¼‚å¸¸æ£€æŸ¥")
    print("   7ï¸âƒ£ ç»Ÿè®¡ä¿¡æ¯è®¡ç®—")
    
    # æ‰§è¡Œæ£€æŸ¥
    report = checker.comprehensive_health_check(df_with_issues, clean_data=True, save_report=False)
    
    # 4. è¾“å‡ºç»“æœ
    print(f"\nğŸ“¤ 4. è¾“å‡ºç»“æœè¯¦è§£")
    print("-" * 50)
    
    print(f"ğŸ¯ æ•´ä½“ç»“æœ:")
    print(f"   å¥åº·çŠ¶æ€: {report.status.value.upper()}")
    print(f"   å‘ç°é—®é¢˜: {len(report.issues)} ä¸ª")
    print(f"   å¤„ç†æ—¶é—´: {report.processing_time:.4f} ç§’")
    print(f"   æ•°æ®å˜åŒ–: {report.original_shape[0]} â†’ {report.cleaned_shape[0]} è¡Œ")
    
    if report.original_shape[0] > 0:
        retention = (report.cleaned_shape[0] / report.original_shape[0]) * 100
        print(f"   æ•°æ®ä¿ç•™ç‡: {retention:.1f}%")
    
    # æ˜¾ç¤ºæ£€æµ‹åˆ°çš„é—®é¢˜
    if report.issues:
        print(f"\nğŸ” æ£€æµ‹åˆ°çš„é—®é¢˜:")
        for i, issue in enumerate(report.issues, 1):
            severity_emoji = "ğŸš¨" if issue.severity.value == "critical" else "âš ï¸"
            print(f"   {i}. {severity_emoji} [{issue.issue_type.value}] {issue.description}")
            if issue.suggestion:
                print(f"      ğŸ’¡ å¤„ç†å»ºè®®: {issue.suggestion}")
    else:
        print(f"\nâœ… æœªå‘ç°ä»»ä½•é—®é¢˜")
    
    # æ˜¾ç¤ºæ¸…æ´—åæ•°æ®
    if report.cleaned_data is not None:
        print(f"\nğŸ“‹ æ¸…æ´—åæ•°æ®:")
        print(f"   æ•°æ®å½¢çŠ¶: {report.cleaned_data.shape}")
        print(f"   æ•°æ®è´¨é‡:")
        print(f"     ç¼ºå¤±å€¼: {report.cleaned_data.isnull().sum().sum()}")
        print(f"     è´Ÿå€¼: {(report.cleaned_data < 0).sum().sum()}")
        print(f"     é›¶å€¼: {(report.cleaned_data == 0).sum().sum()}")
        
        print(f"\n   æ¸…æ´—åé¢„è§ˆ (å‰3è¡Œ):")
        print(report.cleaned_data.head(3).to_string())
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    if report.statistics:
        print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡ä¿¡æ¯:")
        if 'basic' in report.statistics:
            basic = report.statistics['basic']
            print(f"   å†…å­˜ä½¿ç”¨: {basic['memory_usage'] / 1024:.2f} KB")
        
        if 'financial' in report.statistics:
            financial = report.statistics['financial']
            print(f"   ä»·æ ¼æ³¢åŠ¨ç‡: {financial['volatility']:.6f}")
            print(f"   å¹³å‡æ”¶ç›Šç‡: {financial['mean_return']:.6f}")
            print(f"   æ”¶ç›Šç‡èŒƒå›´: {financial['min_return']:.6f} åˆ° {financial['max_return']:.6f}")
    
    # 5. ä¸åŒæ¸…æ´—æ¨¡å¼å¯¹æ¯”
    print(f"\nğŸ§¹ 5. æ¸…æ´—æ¨¡å¼å¯¹æ¯”")
    print("-" * 50)
    
    modes = {
        "ä¿å®ˆæ¨¡å¼": CleaningConfig(
            missing_value_method=CleaningMethod.INTERPOLATE,
            outlier_method=CleaningMethod.MEDIAN_FILL,
            remove_invalid_ohlc=False
        ),
        "æ ‡å‡†æ¨¡å¼": CleaningConfig(
            missing_value_method=CleaningMethod.INTERPOLATE,
            outlier_method=CleaningMethod.MEDIAN_FILL,
            remove_invalid_ohlc=True
        ),
        "ä¸¥æ ¼æ¨¡å¼": CleaningConfig(
            missing_value_method=CleaningMethod.DROP,
            outlier_method=CleaningMethod.DROP,
            remove_invalid_ohlc=True
        )
    }
    
    for mode_name, config in modes.items():
        cleaner = DataCleaner(config)
        cleaned_df, log = cleaner.comprehensive_clean(df_with_issues.copy())
        retention = (len(cleaned_df) / len(df_with_issues)) * 100
        
        print(f"\nğŸ”§ {mode_name}:")
        print(f"   æ•°æ®ä¿ç•™: {len(df_with_issues)} â†’ {len(cleaned_df)} è¡Œ ({retention:.1f}%)")
        print(f"   æ¸…æ´—æ“ä½œ: {len(log)} æ¬¡")
        print(f"   æœ€ç»ˆè´¨é‡:")
        print(f"     ç¼ºå¤±å€¼: {cleaned_df.isnull().sum().sum()}")
        print(f"     è´Ÿå€¼: {(cleaned_df < 0).sum().sum()}")
    
    # 6. è¾“å‡ºæ ¼å¼æ±‡æ€»
    print(f"\nğŸ“‹ 6. å¯ç”¨çš„è¾“å‡ºæ ¼å¼")
    print("-" * 50)
    print("âœ… ä¸»è¦è¾“å‡º:")
    print("   1. report.status - å¥åº·çŠ¶æ€ (healthy/warning/critical/failed)")
    print("   2. report.cleaned_data - æ¸…æ´—åçš„pandas DataFrame")
    print("   3. report.issues - é—®é¢˜åˆ—è¡¨ (ç±»å‹ã€ä¸¥é‡ç¨‹åº¦ã€å»ºè®®)")
    print("   4. report.statistics - è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯")
    print("   5. report.get_summary() - æ‘˜è¦æŠ¥å‘Šå­—å…¸")
    print("   6. report.to_json() - JSONæ ¼å¼æŠ¥å‘Š")
    
    print(f"\nâœ… æ•°æ®æ¸…æ´—å™¨è¾“å‡º:")
    print("   1. cleaned_dataframe - æ¸…æ´—åæ•°æ®")
    print("   2. cleaning_log - è¯¦ç»†æ¸…æ´—æ—¥å¿—")
    print("   3. get_cleaning_summary() - æ¸…æ´—æ‘˜è¦")


if __name__ == "__main__":
    main_demo()
    
    print(f"\n" + "=" * 70)
    print("ğŸ‰ æ¼”ç¤ºå®Œæˆ!")
    print("\nğŸ’¡ æ ¸å¿ƒè¦ç‚¹æ€»ç»“:")
    print("ğŸ“¥ è¾“å…¥: pandas DataFrame (OHLCVæ ¼å¼ + DatetimeIndex)")
    print("ğŸ” æ£€æŸ¥: 7ç±»é—®é¢˜ (ç¼ºå¤±å€¼/å¼‚å¸¸å€¼/æ—¶é—´/é¢‘ç‡/ä»·æ ¼é€»è¾‘/æˆäº¤é‡/ç»Ÿè®¡)")
    print("ğŸ§¹ æ¸…æ´—: 3ç§æ¨¡å¼ (ä¿å®ˆ/æ ‡å‡†/ä¸¥æ ¼)")
    print("ğŸ“¤ è¾“å‡º: æ¸…æ´—æ•°æ® + é—®é¢˜æŠ¥å‘Š + ç»Ÿè®¡ä¿¡æ¯ + å¤„ç†æ—¥å¿—")
    print("âš™ï¸ é…ç½®: å®Œå…¨å¯é…ç½®çš„é˜ˆå€¼å’Œç­–ç•¥")
    print("ğŸ¯ çŠ¶æ€: 4çº§å¥åº·çŠ¶æ€åˆ†çº§ç®¡ç†")
    print("ğŸ“Š æ ¼å¼: DataFrame/å­—å…¸/JSONå¤šç§è¾“å‡ºæ ¼å¼")
    print("\nğŸš€ ç°åœ¨æ‚¨å®Œå…¨æŒæ¡äº†æ•°æ®å¥åº·æ£€æŸ¥å™¨çš„è¾“å…¥è¾“å‡ºï¼")




