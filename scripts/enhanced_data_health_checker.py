"""
å¢å¼ºç‰ˆæ•°æ®å¥åº·æ£€æŸ¥å™¨
æä¾›å…¨é¢çš„æ•°æ®è´¨é‡éªŒè¯å’Œæ¸…æ´—åŠŸèƒ½
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional, Any, Union
from dataclasses import dataclass, field
from enum import Enum
import warnings
import json
from pathlib import Path

# å¯¼å…¥æˆ‘ä»¬çš„å¢å¼ºæ¨¡å—
from enhanced_config_loader import load_config
from logger_config_integration import get_strategy_logger


class HealthStatus(Enum):
    """å¥åº·çŠ¶æ€æšä¸¾"""
    HEALTHY = "healthy"
    WARNING = "warning"
    CRITICAL = "critical"
    FAILED = "failed"


class IssueType(Enum):
    """é—®é¢˜ç±»å‹æšä¸¾"""
    MISSING_VALUES = "missing_values"
    OUTLIERS = "outliers"
    TIME_CONTINUITY = "time_continuity"
    FREQUENCY_CONSISTENCY = "frequency_consistency"
    DATA_RANGE = "data_range"
    VOLUME_ANOMALY = "volume_anomaly"
    PRICE_ANOMALY = "price_anomaly"
    STATISTICAL = "statistical"


@dataclass
class HealthIssue:
    """å¥åº·æ£€æŸ¥é—®é¢˜è®°å½•"""
    issue_type: IssueType
    severity: HealthStatus
    column: str
    description: str
    value: Any = None
    suggestion: str = ""
    timestamp: datetime = field(default_factory=datetime.now)
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            'issue_type': self.issue_type.value,
            'severity': self.severity.value,
            'column': self.column,
            'description': self.description,
            'value': self.value,
            'suggestion': self.suggestion,
            'timestamp': self.timestamp.isoformat()
        }


@dataclass
class HealthReport:
    """å¥åº·æ£€æŸ¥æŠ¥å‘Š"""
    status: HealthStatus
    issues: List[HealthIssue] = field(default_factory=list)
    statistics: Dict[str, Any] = field(default_factory=dict)
    cleaned_data: Optional[pd.DataFrame] = None
    original_shape: Tuple[int, int] = (0, 0)
    cleaned_shape: Tuple[int, int] = (0, 0)
    processing_time: float = 0.0
    timestamp: datetime = field(default_factory=datetime.now)
    
    def add_issue(self, issue: HealthIssue):
        """æ·»åŠ é—®é¢˜"""
        self.issues.append(issue)
        # æ›´æ–°æ•´ä½“çŠ¶æ€
        if issue.severity == HealthStatus.CRITICAL:
            self.status = HealthStatus.CRITICAL
        elif issue.severity == HealthStatus.WARNING and self.status == HealthStatus.HEALTHY:
            self.status = HealthStatus.WARNING
    
    def get_summary(self) -> Dict[str, Any]:
        """è·å–æŠ¥å‘Šæ‘˜è¦"""
        issue_counts = {}
        for issue_type in IssueType:
            issue_counts[issue_type.value] = len([i for i in self.issues if i.issue_type == issue_type])
        
        return {
            'overall_status': self.status.value,
            'total_issues': len(self.issues),
            'critical_issues': len([i for i in self.issues if i.severity == HealthStatus.CRITICAL]),
            'warning_issues': len([i for i in self.issues if i.severity == HealthStatus.WARNING]),
            'issue_breakdown': issue_counts,
            'data_reduction': {
                'original_rows': self.original_shape[0],
                'cleaned_rows': self.cleaned_shape[0],
                'rows_removed': self.original_shape[0] - self.cleaned_shape[0],
                'removal_percentage': ((self.original_shape[0] - self.cleaned_shape[0]) / max(self.original_shape[0], 1)) * 100
            },
            'processing_time_seconds': self.processing_time
        }
    
    def to_json(self) -> str:
        """è½¬æ¢ä¸ºJSONæ ¼å¼"""
        # è½¬æ¢numpyå’Œpandasç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹
        def convert_numpy_types(obj):
            if obj is None:
                return None
            elif isinstance(obj, (np.integer, int)):
                return int(obj)
            elif isinstance(obj, (np.floating, float)):
                return float(obj)
            elif isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, pd.Series):
                return obj.astype(object).to_dict()
            elif hasattr(obj, 'dtype'):  # pandasæ•°æ®ç±»å‹
                return str(obj)
            elif isinstance(obj, dict):
                return {str(key): convert_numpy_types(value) for key, value in obj.items()}
            elif isinstance(obj, (list, tuple)):
                return [convert_numpy_types(item) for item in obj]
            else:
                try:
                    # å°è¯•è½¬æ¢ä¸ºåŸºç¡€ç±»å‹
                    if hasattr(obj, 'item'):
                        return obj.item()
                    else:
                        return str(obj)
                except:
                    return str(obj)
        
        data = {
            'summary': convert_numpy_types(self.get_summary()),
            'issues': [issue.to_dict() for issue in self.issues],
            'statistics': convert_numpy_types(self.statistics),
            'timestamp': self.timestamp.isoformat()
        }
        return json.dumps(data, indent=2, ensure_ascii=False)


class EnhancedDataHealthChecker:
    """
    å¢å¼ºç‰ˆæ•°æ®å¥åº·æ£€æŸ¥å™¨
    
    åŠŸèƒ½ï¼š
    1. ç¼ºå¤±å€¼å¤„ç†
    2. å¼‚å¸¸å€¼æ£€æµ‹
    3. æ—¶é—´è¿ç»­æ€§éªŒè¯
    4. æ•°æ®é¢‘ç‡ä¸€è‡´æ€§
    5. æ•°æ®æ¸…æ´—
    6. è¯¦ç»†æŠ¥å‘Šç”Ÿæˆ
    """
    
    def __init__(self, config: Dict[str, Any] = None, logger=None):
        """
        åˆå§‹åŒ–æ•°æ®å¥åº·æ£€æŸ¥å™¨
        
        Args:
            config: é…ç½®å­—å…¸
            logger: æ—¥å¿—å™¨
        """
        self.config = config or load_config()
        self.logger = logger or get_strategy_logger("data_health_checker")
        
        # ä»é…ç½®ä¸­è·å–é˜ˆå€¼
        self.missing_threshold = self.config.get('DATA_MISSING_THRESHOLD', 0.1)
        self.outlier_threshold = self.config.get('DATA_OUTLIER_THRESHOLD', 3.0)
        self.zero_value_threshold = self.config.get('DATA_ZERO_VALUE_THRESHOLD', 0.05)
        
        self.logger.info("æ•°æ®å¥åº·æ£€æŸ¥å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def check_missing_values(self, df: pd.DataFrame, report: HealthReport) -> pd.DataFrame:
        """
        æ£€æŸ¥å’Œå¤„ç†ç¼ºå¤±å€¼
        
        Args:
            df: è¾“å…¥æ•°æ®æ¡†
            report: å¥åº·æŠ¥å‘Š
            
        Returns:
            å¤„ç†åçš„æ•°æ®æ¡†
        """
        self.logger.debug("å¼€å§‹ç¼ºå¤±å€¼æ£€æŸ¥...")
        
        missing_stats = df.isnull().sum()
        missing_ratios = df.isnull().mean()
        
        # è®°å½•ç»Ÿè®¡ä¿¡æ¯
        report.statistics['missing_values'] = {
            'total_missing': int(missing_stats.sum()),
            'missing_by_column': missing_stats.to_dict(),
            'missing_ratios': missing_ratios.to_dict()
        }
        
        # æ£€æŸ¥æ¯åˆ—çš„ç¼ºå¤±å€¼
        for column in df.columns:
            missing_ratio = missing_ratios[column]
            
            if missing_ratio > self.missing_threshold:
                # ä¸¥é‡ç¼ºå¤±
                issue = HealthIssue(
                    issue_type=IssueType.MISSING_VALUES,
                    severity=HealthStatus.CRITICAL,
                    column=column,
                    description=f"åˆ— {column} ç¼ºå¤±å€¼æ¯”ä¾‹è¿‡é«˜: {missing_ratio:.2%}",
                    value=missing_ratio,
                    suggestion=f"è€ƒè™‘åˆ é™¤è¯¥åˆ—æˆ–ä½¿ç”¨æ’å€¼æ–¹æ³•å¡«å……"
                )
                report.add_issue(issue)
                
                # å¦‚æœæ˜¯ä»·æ ¼æ•°æ®çš„å…³é”®åˆ—ï¼Œå°è¯•æ’å€¼
                if column in ['open', 'high', 'low', 'close']:
                    df[column] = df[column].interpolate(method='linear')
                    self.logger.info(f"å¯¹ä»·æ ¼åˆ— {column} è¿›è¡Œçº¿æ€§æ’å€¼")
                
            elif missing_ratio > 0:
                # è½»å¾®ç¼ºå¤±
                issue = HealthIssue(
                    issue_type=IssueType.MISSING_VALUES,
                    severity=HealthStatus.WARNING,
                    column=column,
                    description=f"åˆ— {column} å­˜åœ¨ç¼ºå¤±å€¼: {missing_ratio:.2%}",
                    value=missing_ratio,
                    suggestion="ä½¿ç”¨å‘å‰å¡«å……æˆ–æ’å€¼æ–¹æ³•å¤„ç†"
                )
                report.add_issue(issue)
                
                # å¤„ç†ç¼ºå¤±å€¼
                if column == 'volume':
                    # æˆäº¤é‡ç”¨0å¡«å……
                    df[column] = df[column].fillna(0)
                elif column in ['open', 'high', 'low', 'close']:
                    # ä»·æ ¼æ•°æ®å‘å‰å¡«å……
                    df[column] = df[column].ffill()
                else:
                    # å…¶ä»–æ•°æ®æ’å€¼
                    df[column] = df[column].interpolate()
        
        # åˆ é™¤ä»ç„¶æœ‰ç¼ºå¤±å€¼çš„è¡Œ
        original_len = len(df)
        df = df.dropna()
        removed_rows = original_len - len(df)
        
        if removed_rows > 0:
            self.logger.info(f"åˆ é™¤äº† {removed_rows} è¡ŒåŒ…å«ç¼ºå¤±å€¼çš„æ•°æ®")
        
        return df
    
    def detect_outliers(self, df: pd.DataFrame, report: HealthReport) -> pd.DataFrame:
        """
        æ£€æµ‹å’Œå¤„ç†å¼‚å¸¸å€¼
        
        Args:
            df: è¾“å…¥æ•°æ®æ¡†
            report: å¥åº·æŠ¥å‘Š
            
        Returns:
            å¤„ç†åçš„æ•°æ®æ¡†
        """
        self.logger.debug("å¼€å§‹å¼‚å¸¸å€¼æ£€æµ‹...")
        
        outlier_stats = {}
        
        # æ£€æŸ¥æ•°å€¼åˆ—çš„å¼‚å¸¸å€¼
        numeric_columns = df.select_dtypes(include=[np.number]).columns
        
        for column in numeric_columns:
            if column in df.columns:
                # ä½¿ç”¨IQRæ–¹æ³•æ£€æµ‹å¼‚å¸¸å€¼
                Q1 = df[column].quantile(0.25)
                Q3 = df[column].quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                
                # ä½¿ç”¨Z-scoreæ–¹æ³• (æ‰‹åŠ¨è®¡ç®—)
                values = df[column].dropna()
                z_scores = np.abs((values - values.mean()) / values.std())
                z_outliers = pd.Series(z_scores > self.outlier_threshold, index=values.index).reindex(df.index, fill_value=False)
                
                # IQRå¼‚å¸¸å€¼
                iqr_outliers = (df[column] < lower_bound) | (df[column] > upper_bound)
                
                # ç»„åˆæ£€æµ‹
                outliers = iqr_outliers | z_outliers
                outlier_count = outliers.sum()
                outlier_ratio = outlier_count / len(df)
                
                outlier_stats[column] = {
                    'count': int(outlier_count),
                    'ratio': float(outlier_ratio),
                    'iqr_bounds': [float(lower_bound), float(upper_bound)],
                    'z_threshold': self.outlier_threshold
                }
                
                if outlier_ratio > 0.05:  # è¶…è¿‡5%ä¸ºå¼‚å¸¸å€¼
                    severity = HealthStatus.CRITICAL if outlier_ratio > 0.1 else HealthStatus.WARNING
                    issue = HealthIssue(
                        issue_type=IssueType.OUTLIERS,
                        severity=severity,
                        column=column,
                        description=f"åˆ— {column} å¼‚å¸¸å€¼æ¯”ä¾‹: {outlier_ratio:.2%}",
                        value=outlier_ratio,
                        suggestion="æ£€æŸ¥æ•°æ®æºï¼Œè€ƒè™‘ä½¿ç”¨ä¸­ä½æ•°æˆ–æ’å€¼æ›¿æ¢å¼‚å¸¸å€¼"
                    )
                    report.add_issue(issue)
                
                # å¤„ç†å¼‚å¸¸å€¼
                if column in ['open', 'high', 'low', 'close']:
                    # ä»·æ ¼å¼‚å¸¸å€¼ç”¨ä¸­ä½æ•°æ›¿æ¢
                    median_val = df[column].median()
                    df.loc[outliers, column] = median_val
                    if outlier_count > 0:
                        self.logger.info(f"ç”¨ä¸­ä½æ•°æ›¿æ¢äº† {outlier_count} ä¸ªä»·æ ¼å¼‚å¸¸å€¼ ({column})")
                
                elif column == 'volume':
                    # æˆäº¤é‡å¼‚å¸¸å€¼æ£€æŸ¥
                    if (df[column] < 0).any():
                        negative_count = (df[column] < 0).sum()
                        issue = HealthIssue(
                            issue_type=IssueType.VOLUME_ANOMALY,
                            severity=HealthStatus.CRITICAL,
                            column=column,
                            description=f"å‘ç° {negative_count} ä¸ªè´Ÿæˆäº¤é‡",
                            value=negative_count,
                            suggestion="å°†è´Ÿæˆäº¤é‡è®¾ç½®ä¸º0æˆ–åˆ é™¤å¯¹åº”è¡Œ"
                        )
                        report.add_issue(issue)
                        # å°†è´Ÿæˆäº¤é‡è®¾ä¸º0
                        df.loc[df[column] < 0, column] = 0
        
        report.statistics['outliers'] = outlier_stats
        return df
    
    def check_time_continuity(self, df: pd.DataFrame, report: HealthReport) -> pd.DataFrame:
        """
        æ£€æŸ¥æ—¶é—´è¿ç»­æ€§
        
        Args:
            df: è¾“å…¥æ•°æ®æ¡†
            report: å¥åº·æŠ¥å‘Š
            
        Returns:
            å¤„ç†åçš„æ•°æ®æ¡†
        """
        self.logger.debug("å¼€å§‹æ—¶é—´è¿ç»­æ€§æ£€æŸ¥...")
        
        if not isinstance(df.index, pd.DatetimeIndex):
            issue = HealthIssue(
                issue_type=IssueType.TIME_CONTINUITY,
                severity=HealthStatus.WARNING,
                column="index",
                description="ç´¢å¼•ä¸æ˜¯æ—¶é—´ç±»å‹",
                suggestion="å°†ç´¢å¼•è½¬æ¢ä¸ºDatetimeIndex"
            )
            report.add_issue(issue)
            return df
        
        # è®¡ç®—æ—¶é—´é—´éš”
        time_diffs = df.index.to_series().diff()
        
        # è¯†åˆ«æ—¶é—´é¢‘ç‡
        mode_diff = time_diffs.mode().iloc[0] if not time_diffs.mode().empty else pd.Timedelta(minutes=30)
        expected_freq = mode_diff
        
        # æ£€æŸ¥æ—¶é—´é—´éš™
        large_gaps = time_diffs > expected_freq * 2
        gap_count = large_gaps.sum()
        
        time_stats = {
            'total_periods': len(df),
            'expected_frequency': str(expected_freq),
            'time_gaps': int(gap_count),
            'gap_ratio': float(gap_count / len(df)),
            'first_timestamp': df.index[0].isoformat(),
            'last_timestamp': df.index[-1].isoformat(),
            'total_duration': str(df.index[-1] - df.index[0])
        }
        
        if gap_count > 0:
            gap_ratio = gap_count / len(df)
            severity = HealthStatus.CRITICAL if gap_ratio > 0.05 else HealthStatus.WARNING
            issue = HealthIssue(
                issue_type=IssueType.TIME_CONTINUITY,
                severity=severity,
                column="index",
                description=f"å‘ç° {gap_count} ä¸ªæ—¶é—´é—´éš™",
                value=gap_count,
                suggestion="è€ƒè™‘å¡«å……ç¼ºå¤±çš„æ—¶é—´ç‚¹æˆ–é‡æ–°é‡‡æ ·æ•°æ®"
            )
            report.add_issue(issue)
        
        # æ£€æŸ¥é‡å¤æ—¶é—´æˆ³
        duplicate_times = df.index.duplicated().sum()
        if duplicate_times > 0:
            issue = HealthIssue(
                issue_type=IssueType.TIME_CONTINUITY,
                severity=HealthStatus.WARNING,
                column="index",
                description=f"å‘ç° {duplicate_times} ä¸ªé‡å¤æ—¶é—´æˆ³",
                value=duplicate_times,
                suggestion="åˆ é™¤æˆ–åˆå¹¶é‡å¤æ—¶é—´æˆ³çš„æ•°æ®"
            )
            report.add_issue(issue)
            # åˆ é™¤é‡å¤æ—¶é—´æˆ³ï¼Œä¿ç•™ç¬¬ä¸€ä¸ª
            df = df[~df.index.duplicated(keep='first')]
        
        time_stats['duplicate_timestamps'] = int(duplicate_times)
        report.statistics['time_continuity'] = time_stats
        
        return df
    
    def check_frequency_consistency(self, df: pd.DataFrame, report: HealthReport) -> pd.DataFrame:
        """
        æ£€æŸ¥æ•°æ®é¢‘ç‡ä¸€è‡´æ€§
        
        Args:
            df: è¾“å…¥æ•°æ®æ¡†
            report: å¥åº·æŠ¥å‘Š
            
        Returns:
            å¤„ç†åçš„æ•°æ®æ¡†
        """
        self.logger.debug("å¼€å§‹é¢‘ç‡ä¸€è‡´æ€§æ£€æŸ¥...")
        
        if not isinstance(df.index, pd.DatetimeIndex) or len(df) < 2:
            return df
        
        # è®¡ç®—æ‰€æœ‰æ—¶é—´é—´éš”
        time_diffs = df.index.to_series().diff().dropna()
        
        # ç»Ÿè®¡ä¸åŒçš„æ—¶é—´é—´éš”
        diff_counts = time_diffs.value_counts()
        most_common_diff = diff_counts.index[0]
        
        # è®¡ç®—é¢‘ç‡ä¸€è‡´æ€§
        consistency_ratio = diff_counts.iloc[0] / len(time_diffs)
        
        freq_stats = {
            'most_common_interval': str(most_common_diff),
            'consistency_ratio': float(consistency_ratio),
            'unique_intervals': len(diff_counts),
            'irregular_periods': int(len(time_diffs) - diff_counts.iloc[0])
        }
        
        if consistency_ratio < 0.9:  # 90%çš„æ•°æ®åº”è¯¥æœ‰ç›¸åŒçš„é¢‘ç‡
            issue = HealthIssue(
                issue_type=IssueType.FREQUENCY_CONSISTENCY,
                severity=HealthStatus.WARNING,
                column="index",
                description=f"æ•°æ®é¢‘ç‡ä¸ä¸€è‡´ï¼Œä¸€è‡´æ€§æ¯”ä¾‹: {consistency_ratio:.2%}",
                value=consistency_ratio,
                suggestion="è€ƒè™‘é‡æ–°é‡‡æ ·åˆ°ç»Ÿä¸€é¢‘ç‡"
            )
            report.add_issue(issue)
        
        report.statistics['frequency_consistency'] = freq_stats
        return df
    
    def check_data_ranges(self, df: pd.DataFrame, report: HealthReport) -> pd.DataFrame:
        """
        æ£€æŸ¥æ•°æ®èŒƒå›´åˆç†æ€§
        
        Args:
            df: è¾“å…¥æ•°æ®æ¡†
            report: å¥åº·æŠ¥å‘Š
            
        Returns:
            å¤„ç†åçš„æ•°æ®æ¡†
        """
        self.logger.debug("å¼€å§‹æ•°æ®èŒƒå›´æ£€æŸ¥...")
        
        range_stats = {}
        
        # æ£€æŸ¥OHLCé€»è¾‘å…³ç³»
        if all(col in df.columns for col in ['open', 'high', 'low', 'close']):
            # Highåº”è¯¥æ˜¯æœ€é«˜çš„
            high_logic = (df['high'] >= df['open']) & (df['high'] >= df['close']) & (df['high'] >= df['low'])
            # Lowåº”è¯¥æ˜¯æœ€ä½çš„
            low_logic = (df['low'] <= df['open']) & (df['low'] <= df['close']) & (df['low'] <= df['high'])
            
            invalid_high = (~high_logic).sum()
            invalid_low = (~low_logic).sum()
            
            if invalid_high > 0:
                issue = HealthIssue(
                    issue_type=IssueType.PRICE_ANOMALY,
                    severity=HealthStatus.CRITICAL,
                    column="high",
                    description=f"å‘ç° {invalid_high} ä¸ªä¸åˆç†çš„æœ€é«˜ä»·",
                    value=invalid_high,
                    suggestion="æ£€æŸ¥æ•°æ®æºï¼Œä¿®æ­£OHLCé€»è¾‘å…³ç³»"
                )
                report.add_issue(issue)
            
            if invalid_low > 0:
                issue = HealthIssue(
                    issue_type=IssueType.PRICE_ANOMALY,
                    severity=HealthStatus.CRITICAL,
                    column="low",
                    description=f"å‘ç° {invalid_low} ä¸ªä¸åˆç†çš„æœ€ä½ä»·",
                    value=invalid_low,
                    suggestion="æ£€æŸ¥æ•°æ®æºï¼Œä¿®æ­£OHLCé€»è¾‘å…³ç³»"
                )
                report.add_issue(issue)
            
            range_stats['ohlc_logic'] = {
                'invalid_high_count': int(invalid_high),
                'invalid_low_count': int(invalid_low),
                'total_rows': len(df)
            }
        
        # æ£€æŸ¥ä»·æ ¼ä¸ºé›¶æˆ–è´Ÿæ•°
        price_columns = ['open', 'high', 'low', 'close']
        for col in price_columns:
            if col in df.columns:
                zero_or_negative = (df[col] <= 0).sum()
                if zero_or_negative > 0:
                    issue = HealthIssue(
                        issue_type=IssueType.PRICE_ANOMALY,
                        severity=HealthStatus.CRITICAL,
                        column=col,
                        description=f"å‘ç° {zero_or_negative} ä¸ªé›¶æˆ–è´Ÿä»·æ ¼",
                        value=zero_or_negative,
                        suggestion="åˆ é™¤æˆ–ä¿®æ­£æ— æ•ˆä»·æ ¼æ•°æ®"
                    )
                    report.add_issue(issue)
                    # åˆ é™¤æ— æ•ˆä»·æ ¼çš„è¡Œ
                    df = df[df[col] > 0]
        
        report.statistics['data_ranges'] = range_stats
        return df
    
    def calculate_statistics(self, df: pd.DataFrame, report: HealthReport):
        """
        è®¡ç®—æ•°æ®ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            df: æ•°æ®æ¡†
            report: å¥åº·æŠ¥å‘Š
        """
        stats_dict = {}
        
        # åŸºç¡€ç»Ÿè®¡
        stats_dict['basic'] = {
            'shape': df.shape,
            'memory_usage': df.memory_usage(deep=True).sum(),
            'dtypes': df.dtypes.to_dict()
        }
        
        # æ•°å€¼åˆ—ç»Ÿè®¡
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 0:
            stats_dict['numeric'] = df[numeric_cols].describe().to_dict()
        
        # æ—¶é—´åºåˆ—ç»Ÿè®¡
        if isinstance(df.index, pd.DatetimeIndex) and len(df) > 0:
            stats_dict['time_series'] = {
                'start_date': df.index[0].isoformat(),
                'end_date': df.index[-1].isoformat(),
                'duration': str(df.index[-1] - df.index[0]),
                'frequency': pd.infer_freq(df.index) if len(df) >= 3 else None
            }
        
        # ç‰¹å®šé‡‘èæŒ‡æ ‡
        if 'close' in df.columns and len(df) > 1:
            returns = df['close'].pct_change().dropna()
            if len(returns) > 0:
                stats_dict['financial'] = {
                    'volatility': float(returns.std()),
                    'mean_return': float(returns.mean()),
                    'max_return': float(returns.max()),
                    'min_return': float(returns.min()),
                    'skewness': float(returns.skew()),
                    'kurtosis': float(returns.kurtosis())
                }
        
        report.statistics.update(stats_dict)
    
    def comprehensive_health_check(self, 
                                 df: pd.DataFrame, 
                                 clean_data: bool = True,
                                 save_report: bool = True,
                                 report_path: str = None) -> HealthReport:
        """
        æ‰§è¡Œå…¨é¢çš„å¥åº·æ£€æŸ¥
        
        Args:
            df: è¾“å…¥æ•°æ®æ¡†
            clean_data: æ˜¯å¦æ¸…æ´—æ•°æ®
            save_report: æ˜¯å¦ä¿å­˜æŠ¥å‘Š
            report_path: æŠ¥å‘Šä¿å­˜è·¯å¾„
            
        Returns:
            å¥åº·æ£€æŸ¥æŠ¥å‘Š
        """
        start_time = datetime.now()
        self.logger.info("å¼€å§‹å…¨é¢æ•°æ®å¥åº·æ£€æŸ¥...")
        
        # åˆå§‹åŒ–æŠ¥å‘Š
        report = HealthReport(
            status=HealthStatus.HEALTHY,
            original_shape=df.shape
        )
        
        # æ£€æŸ¥ç©ºæ•°æ®
        if df.empty:
            issue = HealthIssue(
                issue_type=IssueType.MISSING_VALUES,
                severity=HealthStatus.CRITICAL,
                column="all",
                description="æ•°æ®æ¡†ä¸ºç©º",
                suggestion="æ£€æŸ¥æ•°æ®æºå’Œè·å–è¿‡ç¨‹"
            )
            report.add_issue(issue)
            report.status = HealthStatus.FAILED
            return report
        
        # å¦‚æœéœ€è¦æ¸…æ´—æ•°æ®ï¼Œåˆ›å»ºå‰¯æœ¬
        if clean_data:
            cleaned_df = df.copy()
            
            # æ‰§è¡Œå„é¡¹æ£€æŸ¥å’Œæ¸…æ´—
            cleaned_df = self.check_missing_values(cleaned_df, report)
            cleaned_df = self.detect_outliers(cleaned_df, report)
            cleaned_df = self.check_time_continuity(cleaned_df, report)
            cleaned_df = self.check_frequency_consistency(cleaned_df, report)
            cleaned_df = self.check_data_ranges(cleaned_df, report)
            
            report.cleaned_data = cleaned_df
            report.cleaned_shape = cleaned_df.shape
        else:
            # åªæ£€æŸ¥ä¸æ¸…æ´—
            self.check_missing_values(df, report)
            self.detect_outliers(df, report)
            self.check_time_continuity(df, report)
            self.check_frequency_consistency(df, report)
            self.check_data_ranges(df, report)
            
            report.cleaned_shape = df.shape
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        self.calculate_statistics(df, report)
        
        # è®¡ç®—å¤„ç†æ—¶é—´
        end_time = datetime.now()
        report.processing_time = (end_time - start_time).total_seconds()
        
        # ä¿å­˜æŠ¥å‘Š
        if save_report:
            self.save_report(report, report_path)
        
        self.logger.info(f"æ•°æ®å¥åº·æ£€æŸ¥å®Œæˆï¼ŒçŠ¶æ€: {report.status.value}, å¤„ç†æ—¶é—´: {report.processing_time:.2f}ç§’")
        
        return report
    
    def save_report(self, report: HealthReport, file_path: str = None):
        """
        ä¿å­˜å¥åº·æ£€æŸ¥æŠ¥å‘Š
        
        Args:
            report: å¥åº·æŠ¥å‘Š
            file_path: ä¿å­˜è·¯å¾„
        """
        if file_path is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            file_path = f"scripts/logs/data_health_report_{timestamp}.json"
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        Path(file_path).parent.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜æŠ¥å‘Š
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(report.to_json())
        
        self.logger.info(f"å¥åº·æ£€æŸ¥æŠ¥å‘Šå·²ä¿å­˜åˆ°: {file_path}")
    
    def print_report_summary(self, report: HealthReport):
        """
        æ‰“å°æŠ¥å‘Šæ‘˜è¦
        
        Args:
            report: å¥åº·æŠ¥å‘Š
        """
        summary = report.get_summary()
        
        print("\n" + "=" * 60)
        print("ğŸ“Š æ•°æ®å¥åº·æ£€æŸ¥æŠ¥å‘Šæ‘˜è¦")
        print("=" * 60)
        print(f"ğŸ¯ æ•´ä½“çŠ¶æ€: {summary['overall_status'].upper()}")
        print(f"ğŸ“ˆ æ•°æ®ç»´åº¦: {summary['data_reduction']['original_rows']} è¡Œ â†’ {summary['data_reduction']['cleaned_rows']} è¡Œ")
        print(f"ğŸ—‘ï¸  åˆ é™¤æ•°æ®: {summary['data_reduction']['rows_removed']} è¡Œ ({summary['data_reduction']['removal_percentage']:.1f}%)")
        print(f"â±ï¸  å¤„ç†æ—¶é—´: {summary['processing_time_seconds']:.2f} ç§’")
        print(f"âš ï¸  æ€»é—®é¢˜æ•°: {summary['total_issues']} (ä¸¥é‡: {summary['critical_issues']}, è­¦å‘Š: {summary['warning_issues']})")
        
        if report.issues:
            print("\nğŸ” ä¸»è¦é—®é¢˜:")
            for issue in report.issues[:5]:  # æ˜¾ç¤ºå‰5ä¸ªé—®é¢˜
                status_emoji = "ğŸš¨" if issue.severity == HealthStatus.CRITICAL else "âš ï¸"
                print(f"  {status_emoji} {issue.description}")
                if issue.suggestion:
                    print(f"     ğŸ’¡ å»ºè®®: {issue.suggestion}")
        
        print("=" * 60)


if __name__ == "__main__":
    # æ¼”ç¤ºç”¨æ³•
    from unified_data_client import UnifiedDataClient
    
    print("ğŸ” å¢å¼ºç‰ˆæ•°æ®å¥åº·æ£€æŸ¥å™¨æ¼”ç¤º")
    print("=" * 50)
    
    # åˆ›å»ºæ£€æŸ¥å™¨
    checker = EnhancedDataHealthChecker()
    
    # è·å–æµ‹è¯•æ•°æ®
    try:
        data_client = UnifiedDataClient()
        df = data_client.get_historical_data("AAPL", "30min", limit=100)
        
        print(f"ğŸ“Š è·å–æµ‹è¯•æ•°æ®: {df.shape[0]} è¡Œ x {df.shape[1]} åˆ—")
        
        # æ‰§è¡Œå¥åº·æ£€æŸ¥ (æš‚æ—¶ä¸ä¿å­˜æŠ¥å‘Š)
        report = checker.comprehensive_health_check(df, clean_data=True, save_report=False)
        
        # æ˜¾ç¤ºç»“æœ
        checker.print_report_summary(report)
        
        # ä¿å­˜æ¸…æ´—åçš„æ•°æ®
        if report.cleaned_data is not None:
            print(f"\nâœ… æ¸…æ´—åæ•°æ®å½¢çŠ¶: {report.cleaned_data.shape}")
            print("ğŸ“‹ æ¸…æ´—åæ•°æ®é¢„è§ˆ:")
            print(report.cleaned_data.head())
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        
        # ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®æ¼”ç¤º
        print("\nğŸ­ ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®æ¼”ç¤º...")
        from mock_data_generator import MockDataGenerator
        
        generator = MockDataGenerator()
        df = generator.generate_historical_data("DEMO", "30min", records=50)
        
        # äººå·¥æ·»åŠ ä¸€äº›é—®é¢˜ç”¨äºæ¼”ç¤º
        df.iloc[5:8, 1] = np.nan  # æ·»åŠ ç¼ºå¤±å€¼
        df.iloc[10, 3] = df.iloc[10, 3] * 10  # æ·»åŠ å¼‚å¸¸å€¼
        
        print(f"ğŸ“Š æ¨¡æ‹Ÿæ•°æ®: {df.shape[0]} è¡Œ x {df.shape[1]} åˆ—")
        
        # æ‰§è¡Œå¥åº·æ£€æŸ¥ (æš‚æ—¶ä¸ä¿å­˜æŠ¥å‘Š)
        report = checker.comprehensive_health_check(df, clean_data=True, save_report=False)
        
        # æ˜¾ç¤ºç»“æœ
        checker.print_report_summary(report)
