"""
æ•°æ®æ¸…æ´—å·¥å…·
æä¾›ä¸“ä¸šçš„æ•°æ®æ¸…æ´—å’Œé¢„å¤„ç†åŠŸèƒ½
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple, Any
from enum import Enum
from dataclasses import dataclass
from datetime import datetime

from enhanced_data_health_checker import HealthReport, EnhancedDataHealthChecker
from logger_config_integration import get_strategy_logger


class CleaningMethod(Enum):
    """æ¸…æ´—æ–¹æ³•æšä¸¾"""
    DROP = "drop"
    INTERPOLATE = "interpolate"
    FORWARD_FILL = "forward_fill"
    BACKWARD_FILL = "backward_fill"
    MEDIAN_FILL = "median_fill"
    MEAN_FILL = "mean_fill"
    ZERO_FILL = "zero_fill"


@dataclass
class CleaningConfig:
    """æ¸…æ´—é…ç½®"""
    missing_value_method: CleaningMethod = CleaningMethod.INTERPOLATE
    outlier_method: CleaningMethod = CleaningMethod.MEDIAN_FILL
    negative_volume_method: CleaningMethod = CleaningMethod.ZERO_FILL
    remove_invalid_ohlc: bool = True
    fill_time_gaps: bool = True
    standardize_frequency: bool = True
    target_frequency: str = "30min"


class DataCleaner:
    """
    ä¸“ä¸šæ•°æ®æ¸…æ´—å™¨
    ä¸EnhancedDataHealthCheckeré…åˆä½¿ç”¨
    """
    
    def __init__(self, config: CleaningConfig = None, logger=None):
        """
        åˆå§‹åŒ–æ•°æ®æ¸…æ´—å™¨
        
        Args:
            config: æ¸…æ´—é…ç½®
            logger: æ—¥å¿—å™¨
        """
        self.config = config or CleaningConfig()
        self.logger = logger or get_strategy_logger("data_cleaner")
        self.cleaning_log = []
        
    def log_action(self, action: str, details: str, affected_rows: int = 0):
        """è®°å½•æ¸…æ´—åŠ¨ä½œ"""
        log_entry = {
            'timestamp': datetime.now(),
            'action': action,
            'details': details,
            'affected_rows': affected_rows
        }
        self.cleaning_log.append(log_entry)
        self.logger.info(f"æ•°æ®æ¸…æ´—: {action} - {details} (å½±å“ {affected_rows} è¡Œ)")
    
    def clean_missing_values(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        æ¸…æ´—ç¼ºå¤±å€¼
        
        Args:
            df: è¾“å…¥æ•°æ®æ¡†
            
        Returns:
            æ¸…æ´—åçš„æ•°æ®æ¡†
        """
        original_shape = df.shape
        
        if self.config.missing_value_method == CleaningMethod.DROP:
            df = df.dropna()
            self.log_action("åˆ é™¤ç¼ºå¤±å€¼", "åˆ é™¤åŒ…å«ç¼ºå¤±å€¼çš„è¡Œ", original_shape[0] - df.shape[0])
        
        elif self.config.missing_value_method == CleaningMethod.INTERPOLATE:
            # å¯¹ä»·æ ¼æ•°æ®ä½¿ç”¨çº¿æ€§æ’å€¼
            price_cols = ['open', 'high', 'low', 'close']
            for col in price_cols:
                if col in df.columns:
                    missing_count = df[col].isnull().sum()
                    if missing_count > 0:
                        df[col] = df[col].interpolate(method='linear')
                        self.log_action(f"æ’å€¼å¡«å……-{col}", f"çº¿æ€§æ’å€¼å¡«å……ç¼ºå¤±å€¼", missing_count)
            
            # æˆäº¤é‡ç”¨0å¡«å……
            if 'volume' in df.columns:
                volume_missing = df['volume'].isnull().sum()
                if volume_missing > 0:
                    df['volume'] = df['volume'].fillna(0)
                    self.log_action("æˆäº¤é‡å¡«å……", "ç”¨0å¡«å……ç¼ºå¤±çš„æˆäº¤é‡", volume_missing)
        
        elif self.config.missing_value_method == CleaningMethod.FORWARD_FILL:
            missing_count = df.isnull().sum().sum()
            df = df.fillna(method='ffill')
            self.log_action("å‘å‰å¡«å……", "ä½¿ç”¨å‰ä¸€ä¸ªæœ‰æ•ˆå€¼å¡«å……", missing_count)
        
        elif self.config.missing_value_method == CleaningMethod.MEDIAN_FILL:
            for col in df.select_dtypes(include=[np.number]).columns:
                missing_count = df[col].isnull().sum()
                if missing_count > 0:
                    median_val = df[col].median()
                    df[col] = df[col].fillna(median_val)
                    self.log_action(f"ä¸­ä½æ•°å¡«å……-{col}", f"ç”¨ä¸­ä½æ•° {median_val:.4f} å¡«å……", missing_count)
        
        return df
    
    def clean_outliers(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        æ¸…æ´—å¼‚å¸¸å€¼
        
        Args:
            df: è¾“å…¥æ•°æ®æ¡†
            
        Returns:
            æ¸…æ´—åçš„æ•°æ®æ¡†
        """
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        
        for col in numeric_cols:
            # ä½¿ç”¨IQRæ–¹æ³•è¯†åˆ«å¼‚å¸¸å€¼
            Q1 = df[col].quantile(0.25)
            Q3 = df[col].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            
            outliers = (df[col] < lower_bound) | (df[col] > upper_bound)
            outlier_count = outliers.sum()
            
            if outlier_count > 0:
                if self.config.outlier_method == CleaningMethod.DROP:
                    df = df[~outliers]
                    self.log_action(f"åˆ é™¤å¼‚å¸¸å€¼-{col}", f"åˆ é™¤å¼‚å¸¸å€¼èŒƒå›´å¤–çš„æ•°æ®", outlier_count)
                
                elif self.config.outlier_method == CleaningMethod.MEDIAN_FILL:
                    median_val = df[col].median()
                    df.loc[outliers, col] = median_val
                    self.log_action(f"ä¸­ä½æ•°æ›¿æ¢-{col}", f"ç”¨ä¸­ä½æ•° {median_val:.4f} æ›¿æ¢å¼‚å¸¸å€¼", outlier_count)
                
                elif self.config.outlier_method == CleaningMethod.INTERPOLATE:
                    # å°†å¼‚å¸¸å€¼è®¾ä¸ºNaNç„¶åæ’å€¼
                    df.loc[outliers, col] = np.nan
                    df[col] = df[col].interpolate()
                    self.log_action(f"æ’å€¼æ›¿æ¢-{col}", f"å¼‚å¸¸å€¼æ’å€¼æ›¿æ¢", outlier_count)
        
        return df
    
    def clean_price_logic(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        æ¸…æ´—ä»·æ ¼é€»è¾‘é”™è¯¯
        
        Args:
            df: è¾“å…¥æ•°æ®æ¡†
            
        Returns:
            æ¸…æ´—åçš„æ•°æ®æ¡†
        """
        if not all(col in df.columns for col in ['open', 'high', 'low', 'close']):
            return df
        
        original_len = len(df)
        
        if self.config.remove_invalid_ohlc:
            # æ£€æŸ¥OHLCé€»è¾‘
            valid_high = (df['high'] >= df['open']) & (df['high'] >= df['close']) & (df['high'] >= df['low'])
            valid_low = (df['low'] <= df['open']) & (df['low'] <= df['close']) & (df['low'] <= df['high'])
            valid_prices = (df['open'] > 0) & (df['high'] > 0) & (df['low'] > 0) & (df['close'] > 0)
            
            valid_rows = valid_high & valid_low & valid_prices
            df = df[valid_rows]
            
            removed_rows = original_len - len(df)
            if removed_rows > 0:
                self.log_action("åˆ é™¤æ— æ•ˆOHLC", "åˆ é™¤ä»·æ ¼é€»è¾‘é”™è¯¯çš„è¡Œ", removed_rows)
        
        return df
    
    def clean_volume_anomalies(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        æ¸…æ´—æˆäº¤é‡å¼‚å¸¸
        
        Args:
            df: è¾“å…¥æ•°æ®æ¡†
            
        Returns:
            æ¸…æ´—åçš„æ•°æ®æ¡†
        """
        if 'volume' not in df.columns:
            return df
        
        # å¤„ç†è´Ÿæˆäº¤é‡
        negative_volume = df['volume'] < 0
        negative_count = negative_volume.sum()
        
        if negative_count > 0:
            if self.config.negative_volume_method == CleaningMethod.ZERO_FILL:
                df.loc[negative_volume, 'volume'] = 0
                self.log_action("è´Ÿæˆäº¤é‡å¤„ç†", "å°†è´Ÿæˆäº¤é‡è®¾ä¸º0", negative_count)
            elif self.config.negative_volume_method == CleaningMethod.DROP:
                df = df[~negative_volume]
                self.log_action("åˆ é™¤è´Ÿæˆäº¤é‡", "åˆ é™¤è´Ÿæˆäº¤é‡çš„è¡Œ", negative_count)
        
        return df
    
    def standardize_frequency(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        æ ‡å‡†åŒ–æ•°æ®é¢‘ç‡
        
        Args:
            df: è¾“å…¥æ•°æ®æ¡†
            
        Returns:
            æ ‡å‡†åŒ–åçš„æ•°æ®æ¡†
        """
        if not isinstance(df.index, pd.DatetimeIndex) or not self.config.standardize_frequency:
            return df
        
        original_len = len(df)
        
        try:
            # é‡æ–°é‡‡æ ·åˆ°ç›®æ ‡é¢‘ç‡
            df_resampled = df.resample(self.config.target_frequency).agg({
                'open': 'first',
                'high': 'max',
                'low': 'min',
                'close': 'last',
                'volume': 'sum'
            }).dropna()
            
            new_len = len(df_resampled)
            self.log_action("é¢‘ç‡æ ‡å‡†åŒ–", f"é‡æ–°é‡‡æ ·åˆ° {self.config.target_frequency}", 
                          abs(original_len - new_len))
            
            return df_resampled
            
        except Exception as e:
            self.logger.warning(f"é¢‘ç‡æ ‡å‡†åŒ–å¤±è´¥: {e}")
            return df
    
    def fill_time_gaps(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        å¡«å……æ—¶é—´é—´éš™
        
        Args:
            df: è¾“å…¥æ•°æ®æ¡†
            
        Returns:
            å¡«å……åçš„æ•°æ®æ¡†
        """
        if not isinstance(df.index, pd.DatetimeIndex) or not self.config.fill_time_gaps:
            return df
        
        original_len = len(df)
        
        try:
            # åˆ›å»ºå®Œæ•´çš„æ—¶é—´ç´¢å¼•
            full_index = pd.date_range(
                start=df.index[0], 
                end=df.index[-1], 
                freq=self.config.target_frequency
            )
            
            # é‡æ–°ç´¢å¼•å¹¶å‘å‰å¡«å……
            df_filled = df.reindex(full_index).ffill()
            
            filled_rows = len(df_filled) - original_len
            if filled_rows > 0:
                self.log_action("å¡«å……æ—¶é—´é—´éš™", f"å¡«å…… {filled_rows} ä¸ªæ—¶é—´ç‚¹", filled_rows)
            
            return df_filled
            
        except Exception as e:
            self.logger.warning(f"æ—¶é—´é—´éš™å¡«å……å¤±è´¥: {e}")
            return df
    
    def comprehensive_clean(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, List[Dict]]:
        """
        æ‰§è¡Œå…¨é¢æ•°æ®æ¸…æ´—
        
        Args:
            df: è¾“å…¥æ•°æ®æ¡†
            
        Returns:
            æ¸…æ´—åçš„æ•°æ®æ¡†å’Œæ¸…æ´—æ—¥å¿—
        """
        self.logger.info("å¼€å§‹å…¨é¢æ•°æ®æ¸…æ´—...")
        self.cleaning_log.clear()
        
        original_shape = df.shape
        self.log_action("å¼€å§‹æ¸…æ´—", f"åŸå§‹æ•°æ®å½¢çŠ¶: {original_shape}", 0)
        
        # æ‰§è¡Œæ¸…æ´—æ­¥éª¤
        df = self.clean_missing_values(df)
        df = self.clean_price_logic(df)
        df = self.clean_volume_anomalies(df)
        df = self.clean_outliers(df)
        
        # æ—¶é—´ç›¸å…³æ¸…æ´—
        if isinstance(df.index, pd.DatetimeIndex):
            df = self.standardize_frequency(df)
            df = self.fill_time_gaps(df)
        
        final_shape = df.shape
        total_removed = original_shape[0] - final_shape[0]
        self.log_action("æ¸…æ´—å®Œæˆ", f"æœ€ç»ˆæ•°æ®å½¢çŠ¶: {final_shape}", total_removed)
        
        self.logger.info(f"æ•°æ®æ¸…æ´—å®Œæˆ: {original_shape} â†’ {final_shape}")
        
        return df, self.cleaning_log.copy()
    
    def get_cleaning_summary(self) -> Dict[str, Any]:
        """
        è·å–æ¸…æ´—æ‘˜è¦
        
        Returns:
            æ¸…æ´—æ‘˜è¦å­—å…¸
        """
        if not self.cleaning_log:
            return {}
        
        total_affected = sum(entry['affected_rows'] for entry in self.cleaning_log)
        action_counts = {}
        
        for entry in self.cleaning_log:
            action = entry['action']
            action_counts[action] = action_counts.get(action, 0) + 1
        
        return {
            'total_actions': len(self.cleaning_log),
            'total_affected_rows': total_affected,
            'action_breakdown': action_counts,
            'start_time': self.cleaning_log[0]['timestamp'].isoformat() if self.cleaning_log else None,
            'end_time': self.cleaning_log[-1]['timestamp'].isoformat() if self.cleaning_log else None,
            'detailed_log': self.cleaning_log
        }


def create_integrated_data_processor():
    """
    åˆ›å»ºé›†æˆçš„æ•°æ®å¤„ç†å™¨ï¼ˆå¥åº·æ£€æŸ¥ + æ¸…æ´—ï¼‰
    
    Returns:
        é›†æˆå¤„ç†å‡½æ•°
    """
    def process_data(df: pd.DataFrame, 
                    cleaning_config: CleaningConfig = None,
                    save_reports: bool = True) -> Tuple[pd.DataFrame, HealthReport, List[Dict]]:
        """
        é›†æˆæ•°æ®å¤„ç†æµç¨‹
        
        Args:
            df: è¾“å…¥æ•°æ®
            cleaning_config: æ¸…æ´—é…ç½®
            save_reports: æ˜¯å¦ä¿å­˜æŠ¥å‘Š
            
        Returns:
            (æ¸…æ´—åæ•°æ®, å¥åº·æŠ¥å‘Š, æ¸…æ´—æ—¥å¿—)
        """
        # å¥åº·æ£€æŸ¥
        health_checker = EnhancedDataHealthChecker()
        health_report = health_checker.comprehensive_health_check(
            df, clean_data=False, save_report=save_reports
        )
        
        # æ•°æ®æ¸…æ´—
        cleaner = DataCleaner(cleaning_config)
        cleaned_df, cleaning_log = cleaner.comprehensive_clean(df)
        
        # å¯¹æ¸…æ´—åæ•°æ®å†æ¬¡æ£€æŸ¥
        final_report = health_checker.comprehensive_health_check(
            cleaned_df, clean_data=False, save_report=save_reports
        )
        
        return cleaned_df, final_report, cleaning_log
    
    return process_data


if __name__ == "__main__":
    # æ¼”ç¤ºæ•°æ®æ¸…æ´—å™¨
    print("ğŸ§¹ æ•°æ®æ¸…æ´—å™¨æ¼”ç¤º")
    print("=" * 50)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    from mock_data_generator import MockDataGenerator
    
    generator = MockDataGenerator()
    df = generator.generate_historical_data("TEST", "30min", records=100)
    
    # äººå·¥æ·»åŠ é—®é¢˜
    print("ğŸ“Š æ·»åŠ æ•°æ®é—®é¢˜ç”¨äºæ¼”ç¤º...")
    df.iloc[10:15, 1] = np.nan  # ç¼ºå¤±å€¼
    df.iloc[20, 3] = df.iloc[20, 3] * 20  # å¼‚å¸¸å€¼
    df.iloc[30:32, :] = 0  # é›¶å€¼
    df.loc[df.index[5], 'volume'] = -1000  # è´Ÿæˆäº¤é‡
    
    print(f"åŸå§‹æ•°æ®å½¢çŠ¶: {df.shape}")
    print(f"ç¼ºå¤±å€¼æ•°é‡: {df.isnull().sum().sum()}")
    
    # åˆ›å»ºæ¸…æ´—é…ç½®
    config = CleaningConfig(
        missing_value_method=CleaningMethod.INTERPOLATE,
        outlier_method=CleaningMethod.MEDIAN_FILL,
        negative_volume_method=CleaningMethod.ZERO_FILL,
        remove_invalid_ohlc=True,
        standardize_frequency=True,
        target_frequency="30min"
    )
    
    # æ‰§è¡Œæ¸…æ´—
    cleaner = DataCleaner(config)
    cleaned_df, cleaning_log = cleaner.comprehensive_clean(df)
    
    print(f"\næ¸…æ´—åæ•°æ®å½¢çŠ¶: {cleaned_df.shape}")
    print(f"æ¸…æ´—åç¼ºå¤±å€¼: {cleaned_df.isnull().sum().sum()}")
    
    # æ˜¾ç¤ºæ¸…æ´—æ‘˜è¦
    summary = cleaner.get_cleaning_summary()
    print(f"\nğŸ§¹ æ¸…æ´—æ‘˜è¦:")
    print(f"æ€»æ“ä½œæ•°: {summary['total_actions']}")
    print(f"å½±å“è¡Œæ•°: {summary['total_affected_rows']}")
    print(f"æ“ä½œç±»å‹: {list(summary['action_breakdown'].keys())}")
    
    print("\nâœ… æ•°æ®æ¸…æ´—æ¼”ç¤ºå®Œæˆï¼")
