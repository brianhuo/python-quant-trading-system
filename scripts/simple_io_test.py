"""
ç®€åŒ–çš„è¾“å…¥è¾“å‡ºæµ‹è¯•
æ¸…æ™°å±•ç¤ºDataHealthCheckerçš„è¾“å…¥è¾“å‡º
"""

import pandas as pd
import numpy as np
from datetime import datetime

from enhanced_data_health_checker import EnhancedDataHealthChecker
from data_cleaner import DataCleaner, CleaningConfig, CleaningMethod
from mock_data_generator import MockDataGenerator


def demo_basic_input_output():
    """æ¼”ç¤ºåŸºæœ¬è¾“å…¥è¾“å‡º"""
    print("ğŸ“Š æ•°æ®å¥åº·æ£€æŸ¥å™¨ - åŸºæœ¬è¾“å…¥è¾“å‡ºæ¼”ç¤º")
    print("="*60)
    
    print("\nğŸ”§ 1. è¾“å…¥æ•°æ®è¦æ±‚:")
    print("   âœ… pandas DataFrame")
    print("   âœ… åŒ…å«OHLCVåˆ— (open, high, low, close, volume)")
    print("   âœ… DatetimeIndexæ—¶é—´ç´¢å¼• (æ¨è)")
    print("   âœ… æ•°å€¼å‹æ•°æ®")
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    generator = MockDataGenerator()
    df = generator.generate_historical_data("DEMO", "30min", records=20)
    
    print(f"\nğŸ“¥ è¾“å…¥ç¤ºä¾‹:")
    print(f"   æ•°æ®ç±»å‹: {type(df)}")
    print(f"   æ•°æ®å½¢çŠ¶: {df.shape}")
    print(f"   åˆ—å: {list(df.columns)}")
    print(f"   æ—¶é—´è·¨åº¦: {df.index[0]} åˆ° {df.index[-1]}")
    print(f"\n   å‰3è¡Œæ•°æ®:")
    print(df.head(3).to_string())
    
    # æ·»åŠ ä¸€äº›é—®é¢˜ç”¨äºæ¼”ç¤º
    print(f"\nğŸ”§ 2. æ¨¡æ‹Ÿæ•°æ®é—®é¢˜:")
    df_with_issues = df.copy()
    df_with_issues.iloc[5, 1] = np.nan  # ç¼ºå¤±å€¼
    df_with_issues.iloc[8, 3] = df_with_issues.iloc[8, 3] * 10  # å¼‚å¸¸å€¼
    df_with_issues.iloc[12, 4] = -500  # è´Ÿæˆäº¤é‡
    
    print("   â• æ·»åŠ ç¼ºå¤±å€¼ (ç¬¬6è¡Œ, highåˆ—)")
    print("   â• æ·»åŠ å¼‚å¸¸å€¼ (ç¬¬9è¡Œ, closeåˆ—, 10å€ä»·æ ¼)")
    print("   â• æ·»åŠ è´Ÿæˆäº¤é‡ (ç¬¬13è¡Œ, volumeåˆ—)")
    
    # æ‰§è¡Œå¥åº·æ£€æŸ¥
    print(f"\nğŸ” 3. æ‰§è¡Œå¥åº·æ£€æŸ¥:")
    checker = EnhancedDataHealthChecker()
    report = checker.comprehensive_health_check(df_with_issues, clean_data=True, save_report=False)
    
    print(f"\nğŸ“¤ 4. è¾“å‡ºç»“æœ:")
    print(f"   çŠ¶æ€çº§åˆ«: {report.status.value}")
    print(f"   å‘ç°é—®é¢˜: {len(report.issues)} ä¸ª")
    print(f"   å¤„ç†è€—æ—¶: {report.processing_time:.4f} ç§’")
    print(f"   åŸå§‹æ•°æ®: {report.original_shape[0]} è¡Œ Ã— {report.original_shape[1]} åˆ—")
    print(f"   æ¸…æ´—å: {report.cleaned_shape[0]} è¡Œ Ã— {report.cleaned_shape[1]} åˆ—")
    
    if report.issues:
        print(f"\n   ğŸ” æ£€æµ‹åˆ°çš„é—®é¢˜:")
        for i, issue in enumerate(report.issues, 1):
            severity = "ğŸš¨" if issue.severity.value == "critical" else "âš ï¸"
            print(f"     {i}. {severity} {issue.description}")
    
    if report.cleaned_data is not None:
        print(f"\n   ğŸ“‹ æ¸…æ´—åæ•°æ®é¢„è§ˆ:")
        print(report.cleaned_data.head(3).to_string())
        print(f"\n   âœ… æ¸…æ´—æ•ˆæœ:")
        print(f"     ç¼ºå¤±å€¼: {report.cleaned_data.isnull().sum().sum()}")
        print(f"     è´Ÿå€¼æ•°é‡: {(report.cleaned_data < 0).sum().sum()}")


def demo_different_data_scenarios():
    """æ¼”ç¤ºä¸åŒæ•°æ®åœºæ™¯"""
    print(f"\n\nğŸ§ª ä¸åŒæ•°æ®åœºæ™¯æµ‹è¯•")
    print("="*60)
    
    checker = EnhancedDataHealthChecker()
    
    scenarios = [
        ("å®Œç¾æ•°æ®", "æ— ä»»ä½•é—®é¢˜çš„ç†æƒ³æ•°æ®"),
        ("ç¼ºå¤±å€¼æ•°æ®", "åŒ…å«å„ç§ç¼ºå¤±å€¼"),
        ("å¼‚å¸¸å€¼æ•°æ®", "åŒ…å«ä»·æ ¼å’Œæˆäº¤é‡å¼‚å¸¸"),
        ("æ—¶é—´é—®é¢˜æ•°æ®", "æ—¶é—´é—´éš™å’Œé‡å¤æ—¶é—´æˆ³"),
    ]
    
    for i, (name, description) in enumerate(scenarios, 1):
        print(f"\nğŸ“ åœºæ™¯ {i}: {name}")
        print(f"   æè¿°: {description}")
        
        # åˆ›å»ºå¯¹åº”çš„æµ‹è¯•æ•°æ®
        generator = MockDataGenerator()
        test_df = generator.generate_historical_data(f"TEST{i}", "30min", records=20)
        
        if name == "ç¼ºå¤±å€¼æ•°æ®":
            test_df.iloc[3:6, 1] = np.nan
            test_df.iloc[8, 3] = np.nan
        elif name == "å¼‚å¸¸å€¼æ•°æ®":
            test_df.iloc[5, 1] = test_df.iloc[5, 1] * 20
            test_df.iloc[10, 4] = -1000
        elif name == "æ—¶é—´é—®é¢˜æ•°æ®":
            test_df = test_df.drop(test_df.index[8:12])  # åˆ é™¤æ—¶é—´ç‚¹
        
        # æ‰§è¡Œæ£€æŸ¥
        report = checker.comprehensive_health_check(test_df, clean_data=True, save_report=False)
        
        # æ˜¾ç¤ºç»“æœ
        print(f"   ğŸ“Š è¾“å…¥: {test_df.shape[0]} è¡Œ")
        print(f"   ğŸ“Š è¾“å‡º: {report.cleaned_shape[0]} è¡Œ")
        print(f"   ğŸ¯ çŠ¶æ€: {report.status.value}")
        print(f"   âš ï¸ é—®é¢˜: {len(report.issues)} ä¸ª")


def demo_cleaner_modes():
    """æ¼”ç¤ºä¸åŒæ¸…æ´—æ¨¡å¼"""
    print(f"\n\nğŸ§¹ æ•°æ®æ¸…æ´—æ¨¡å¼å¯¹æ¯”")
    print("="*60)
    
    # åˆ›å»ºæœ‰é—®é¢˜çš„æ•°æ®
    generator = MockDataGenerator()
    dirty_data = generator.generate_historical_data("DIRTY", "30min", records=30)
    
    # æ·»åŠ å„ç§é—®é¢˜
    dirty_data.iloc[5:8, 1] = np.nan  # ç¼ºå¤±å€¼
    dirty_data.iloc[10, 3] = dirty_data.iloc[10, 3] * 50  # å¼‚å¸¸å€¼
    dirty_data.iloc[15, 4] = -2000  # è´Ÿæˆäº¤é‡
    dirty_data.iloc[20, 0] = 0  # é›¶å¼€ç›˜ä»·
    
    print(f"ğŸ“¥ åŸå§‹é—®é¢˜æ•°æ®:")
    print(f"   æ•°æ®å½¢çŠ¶: {dirty_data.shape}")
    print(f"   ç¼ºå¤±å€¼: {dirty_data.isnull().sum().sum()}")
    print(f"   è´Ÿå€¼: {(dirty_data < 0).sum().sum()}")
    print(f"   é›¶å€¼: {(dirty_data == 0).sum().sum()}")
    
    # æµ‹è¯•ä¸åŒæ¨¡å¼
    modes = {
        "ä¿å®ˆæ¨¡å¼": CleaningConfig(
            missing_value_method=CleaningMethod.INTERPOLATE,
            outlier_method=CleaningMethod.MEDIAN_FILL,
            remove_invalid_ohlc=False
        ),
        "å¹³è¡¡æ¨¡å¼": CleaningConfig(
            missing_value_method=CleaningMethod.INTERPOLATE,
            outlier_method=CleaningMethod.MEDIAN_FILL,
            remove_invalid_ohlc=True
        ),
        "ä¸¥æ ¼æ¨¡å¼": CleaningConfig(
            missing_value_method=CleaningMethod.DROP,
            outlier_method=CleaningMethod.DROP,
            remove_invalid_ohlc=True
        )
    }
    
    for mode_name, config in modes.items():
        print(f"\nğŸ”§ {mode_name}:")
        cleaner = DataCleaner(config)
        cleaned_df, _ = cleaner.comprehensive_clean(dirty_data.copy())
        
        retention_rate = (len(cleaned_df) / len(dirty_data)) * 100
        
        print(f"   ğŸ“Š ç»“æœ: {dirty_data.shape[0]} â†’ {cleaned_df.shape[0]} è¡Œ")
        print(f"   ğŸ“ˆ ä¿ç•™ç‡: {retention_rate:.1f}%")
        print(f"   âœ… æ¸…æ´—æ•ˆæœ:")
        print(f"     ç¼ºå¤±å€¼: {cleaned_df.isnull().sum().sum()}")
        print(f"     è´Ÿå€¼: {(cleaned_df < 0).sum().sum()}")
        print(f"     é›¶å€¼: {(cleaned_df == 0).sum().sum()}")


def demo_output_formats():
    """æ¼”ç¤ºè¾“å‡ºæ ¼å¼"""
    print(f"\n\nğŸ“„ è¾“å‡ºæ ¼å¼æ¼”ç¤º")
    print("="*60)
    
    generator = MockDataGenerator()
    test_data = generator.generate_historical_data("OUTPUT_TEST", "30min", records=15)
    test_data.iloc[3, 1] = np.nan  # æ·»åŠ ä¸€ä¸ªé—®é¢˜
    
    checker = EnhancedDataHealthChecker()
    report = checker.comprehensive_health_check(test_data, clean_data=True, save_report=False)
    
    print("ğŸ“Š å¯ç”¨çš„è¾“å‡ºæ ¼å¼:")
    
    # 1. æŠ¥å‘Šæ‘˜è¦
    print("\n1ï¸âƒ£ æŠ¥å‘Šæ‘˜è¦ (get_summary()):")
    summary = report.get_summary()
    for key, value in summary.items():
        if isinstance(value, dict):
            print(f"   {key}:")
            for sub_key, sub_value in value.items():
                print(f"     {sub_key}: {sub_value}")
        else:
            print(f"   {key}: {value}")
    
    # 2. æ¸…æ´—åæ•°æ®
    print(f"\n2ï¸âƒ£ æ¸…æ´—åæ•°æ® (cleaned_data):")
    if report.cleaned_data is not None:
        print(f"   ç±»å‹: {type(report.cleaned_data)}")
        print(f"   å½¢çŠ¶: {report.cleaned_data.shape}")
        print("   å‰3è¡Œ:")
        print(report.cleaned_data.head(3).to_string())
    
    # 3. é—®é¢˜åˆ—è¡¨
    print(f"\n3ï¸âƒ£ é—®é¢˜è¯¦æƒ… (issues):")
    for i, issue in enumerate(report.issues, 1):
        print(f"   é—®é¢˜ {i}:")
        print(f"     ç±»å‹: {issue.issue_type.value}")
        print(f"     ä¸¥é‡ç¨‹åº¦: {issue.severity.value}")
        print(f"     åˆ—: {issue.column}")
        print(f"     æè¿°: {issue.description}")
    
    # 4. ç»Ÿè®¡ä¿¡æ¯
    print(f"\n4ï¸âƒ£ ç»Ÿè®¡ä¿¡æ¯ (statistics):")
    if 'basic' in report.statistics:
        print(f"   æ•°æ®å½¢çŠ¶: {report.statistics['basic']['shape']}")
        print(f"   å†…å­˜ä½¿ç”¨: {report.statistics['basic']['memory_usage'] / 1024:.2f} KB")
    
    if 'financial' in report.statistics:
        financial = report.statistics['financial']
        print(f"   ä»·æ ¼æ³¢åŠ¨ç‡: {financial['volatility']:.6f}")
        print(f"   å¹³å‡æ”¶ç›Šç‡: {financial['mean_return']:.6f}")


if __name__ == "__main__":
    print("ğŸš€ æ•°æ®å¥åº·æ£€æŸ¥å™¨ - è¾“å…¥è¾“å‡ºæµ‹è¯•")
    print("ç›®æ ‡ï¼šæ¸…æ™°å±•ç¤ºè¾“å…¥ä»€ä¹ˆï¼Œè¾“å‡ºä»€ä¹ˆ")
    
    demo_basic_input_output()
    demo_different_data_scenarios()
    demo_cleaner_modes()
    demo_output_formats()
    
    print(f"\n" + "="*60)
    print("ğŸ‰ æµ‹è¯•å®Œæˆ!")
    print("\nğŸ’¡ æ ¸å¿ƒè¦ç‚¹:")
    print("ğŸ“¥ è¾“å…¥: pandas DataFrame (OHLCVæ ¼å¼)")
    print("ğŸ” å¤„ç†: 7ç±»é—®é¢˜æ£€æµ‹ + æ™ºèƒ½æ¸…æ´—")
    print("ğŸ“¤ è¾“å‡º: æ¸…æ´—åæ•°æ® + è¯¦ç»†æŠ¥å‘Š + ç»Ÿè®¡ä¿¡æ¯")
    print("âš™ï¸ é…ç½®: çµæ´»çš„æ¸…æ´—ç­–ç•¥å’Œé˜ˆå€¼è®¾ç½®")
    print("ğŸ¯ çŠ¶æ€: 4çº§å¥åº·çŠ¶æ€ (healthy/warning/critical/failed)")
    print("\nğŸš€ ç°åœ¨æ‚¨å®Œå…¨äº†è§£äº†æ•°æ®å¥åº·æ£€æŸ¥å™¨çš„è¾“å…¥è¾“å‡ºï¼")



