# Enhanced ModelTrainer V2 ä¼˜åŒ–æŠ¥å‘Š

## æ¦‚è¿°

å¯¹ `EnhancedModelTrainer` è¿›è¡Œäº†å…¨é¢é‡æ„å’Œå‡çº§ï¼Œå®ç°äº†å¤šæ¨¡å‹æ”¯æŒã€æ™ºèƒ½ç‰¹å¾é€‰æ‹©ã€å®Œæ•´ç‰ˆæœ¬ç®¡ç†ç­‰å…ˆè¿›åŠŸèƒ½ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹è®­ç»ƒçš„è‡ªåŠ¨åŒ–ç¨‹åº¦å’Œæ•ˆæœã€‚

## ä¼˜åŒ–å†…å®¹

### 1. å¤šç§æ¨¡å‹æ”¯æŒ âœ…

#### æ”¯æŒçš„æ¨¡å‹ç±»å‹
```python
# åŸç‰ˆï¼šåªæ”¯æŒLightGBM
# ä¼˜åŒ–åï¼šæ”¯æŒå¤šç§æ¨¡å‹
model_types = {
    'lightgbm': 'LightGBMåˆ†ç±»å™¨',
    'xgboost': 'XGBooståˆ†ç±»å™¨', 
    'random_forest': 'éšæœºæ£®æ—åˆ†ç±»å™¨',
    'ensemble': 'æ¨¡å‹é›†æˆ (è§„åˆ’ä¸­)'
}
```

#### æ¨¡å‹å·¥å‚æ¨¡å¼
```python
class ModelFactory:
    @staticmethod
    def create_model(model_type: str, config: ModelConfig):
        """ç»Ÿä¸€çš„æ¨¡å‹åˆ›å»ºæ¥å£"""
        if model_type == 'lightgbm':
            return ModelFactory._create_lightgbm(config)
        elif model_type == 'xgboost':
            return ModelFactory._create_xgboost(config)
        # ...
```

### 2. æ™ºèƒ½ç‰¹å¾é€‰æ‹© âœ…

#### å¤šç§é€‰æ‹©ç­–ç•¥
```python
feature_selection_methods = {
    'auto': 'è‡ªåŠ¨é€‰æ‹©ï¼ˆç»„åˆå¤šç§æ–¹æ³•ï¼‰',
    'importance': 'åŸºäºç‰¹å¾é‡è¦æ€§',
    'statistical': 'ç»Ÿè®¡æ˜¾è‘—æ€§æµ‹è¯•',
    'mutual_info': 'äº’ä¿¡æ¯æ–¹æ³•'
}
```

#### è‡ªåŠ¨ç‰¹å¾é€‰æ‹©ç®—æ³•
```python
def _auto_selection(self, X, y, feature_names):
    """æ™ºèƒ½ç»„åˆå¤šç§ç‰¹å¾é€‰æ‹©æ–¹æ³•"""
    # 1. é‡è¦æ€§æ–¹æ³•
    X_imp, features_imp = self._importance_selection(X, y, feature_names)
    
    # 2. ç»Ÿè®¡æ–¹æ³•  
    X_stat, features_stat = self._statistical_selection(X, y, feature_names)
    
    # 3. å–äº¤é›†å¹¶è¡¥å……
    common_features = set(features_imp) & set(features_stat)
    # ...æ™ºèƒ½é€‰æ‹©é€»è¾‘
```

### 3. æ¨¡å‹ç‰ˆæœ¬ç®¡ç†ç³»ç»Ÿ âœ…

#### å®Œæ•´çš„ç‰ˆæœ¬ä¿¡æ¯
```python
@dataclass
class ModelVersion:
    version: str              # ç‰ˆæœ¬å·
    model_type: str          # æ¨¡å‹ç±»å‹
    created_at: datetime     # åˆ›å»ºæ—¶é—´
    config: Dict             # é…ç½®å‚æ•°
    metrics: Dict            # æ€§èƒ½æŒ‡æ ‡
    feature_names: List[str] # ç‰¹å¾åç§°
    data_hash: str           # æ•°æ®å“ˆå¸Œ
    model_path: str          # æ¨¡å‹è·¯å¾„
    description: str         # æè¿°ä¿¡æ¯
```

#### ç‰ˆæœ¬ç®¡ç†åŠŸèƒ½
- **è‡ªåŠ¨ç‰ˆæœ¬æ§åˆ¶**: åŸºäºæ—¶é—´æˆ³å’Œæ•°æ®å“ˆå¸Œçš„ç‰ˆæœ¬ID
- **æ¨¡å‹æ³¨å†Œè¡¨**: JSONæ ¼å¼çš„æ¨¡å‹æ³¨å†Œè¡¨
- **æœ€ä½³æ¨¡å‹è¿½è¸ª**: æ ¹æ®æŒ‡æ ‡è‡ªåŠ¨è¯†åˆ«æœ€ä½³æ¨¡å‹
- **ç‰ˆæœ¬æŸ¥è¯¢**: çµæ´»çš„æ¨¡å‹æŸ¥è¯¢å’Œæ¯”è¾ƒåŠŸèƒ½

### 4. è¶…å‚æ•°è‡ªåŠ¨ä¼˜åŒ– âœ…

#### Optunaé›†æˆ
```python
class OptunaTuner:
    def optimize(self, X_train, y_train):
        """ä½¿ç”¨Optunaè¿›è¡Œè¶…å‚æ•°ä¼˜åŒ–"""
        study = optuna.create_study(direction='maximize')
        study.optimize(objective, n_trials=self.n_trials)
        return study.best_params
```

#### æ¨¡å‹ç‰¹å®šçš„å‚æ•°ç©ºé—´
- **LightGBM**: learning_rate, max_depth, num_leaves, reg_alphaç­‰
- **XGBoost**: learning_rate, max_depth, min_child_weight, reg_alphaç­‰  
- **RandomForest**: n_estimators, max_depth, min_samples_splitç­‰

### 5. å…¨é¢çš„æ¨¡å‹è¯„ä¼° âœ…

#### å¤šç»´åº¦è¯„ä¼°æŒ‡æ ‡
```python
evaluation_metrics = {
    'accuracy': 'å‡†ç¡®ç‡',
    'f1_score': 'F1åˆ†æ•°',
    'precision': 'ç²¾ç¡®ç‡', 
    'recall': 'å¬å›ç‡',
    'auc': 'AUCåˆ†æ•°',
    'classification_report': 'è¯¦ç»†åˆ†ç±»æŠ¥å‘Š',
    'confusion_matrix': 'æ··æ·†çŸ©é˜µ'
}
```

#### å¯è§†åŒ–å’Œè§£é‡Š
- **SHAPå€¼åˆ†æ**: ç‰¹å¾é‡è¦æ€§è§£é‡Š
- **å­¦ä¹ æ›²çº¿**: è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–
- **æ··æ·†çŸ©é˜µ**: åˆ†ç±»ç»“æœåˆ†æ
- **ç‰¹å¾é‡è¦æ€§å›¾**: ç‰¹å¾è´¡çŒ®åˆ†æ

### 6. é…ç½®é©±åŠ¨çš„è®¾è®¡ âœ…

#### å®Œæ•´çš„é…ç½®ç±»
```python
@dataclass
class ModelConfig:
    # æ¨¡å‹é€‰æ‹©
    model_type: str = 'lightgbm'
    
    # ç‰¹å¾é€‰æ‹©
    feature_selection_method: str = 'auto'
    n_features: int = 20
    
    # è®­ç»ƒå‚æ•°
    cv_folds: int = 5
    use_optuna: bool = True
    optuna_trials: int = 100
    
    # æ¨¡å‹ç‰¹å®šå‚æ•°
    lgb_params: Dict = None
    xgb_params: Dict = None
```

## ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€ç”¨æ³•
```python
from enhanced_model_trainer_v2 import EnhancedModelTrainer, ModelConfig

# åˆ›å»ºé…ç½®
config = ModelConfig(
    model_type='lightgbm',
    feature_selection_method='auto',
    n_features=15,
    use_optuna=True,
    optuna_trials=50
)

# åˆ›å»ºè®­ç»ƒå™¨
trainer = EnhancedModelTrainer(config=config, logger=logger)

# è®­ç»ƒæ¨¡å‹
result = trainer.train(X_train, y_train, X_test, y_test, feature_names)
```

### é«˜çº§ç”¨æ³•
```python
# æ¨¡å‹å¯¹æ¯”
models_to_compare = ['lightgbm', 'xgboost', 'random_forest']
results = {}

for model_type in models_to_compare:
    config = ModelConfig(model_type=model_type)
    trainer = EnhancedModelTrainer(config=config)
    results[model_type] = trainer.train(X_train, y_train, X_test, y_test)

# ç‰ˆæœ¬ç®¡ç†
version_manager = ModelVersionManager()
best_version = version_manager.get_best_model('f1_score')
model_info = version_manager.get_model_info(best_version)
```

## æ€§èƒ½æå‡å¯¹æ¯”

### åŠŸèƒ½å®Œæ•´æ€§å¯¹æ¯”

| åŠŸèƒ½æ¨¡å— | åŸç‰ˆæ”¯æŒ | ä¼˜åŒ–åæ”¯æŒ | æ”¹è¿›ç¨‹åº¦ |
|---------|---------|-----------|---------|
| **æ¨¡å‹ç±»å‹** | 1ç§(LGBM) | **3ç§+æ‰©å±•æ¶æ„** | â¬†ï¸ **300%+** |
| **ç‰¹å¾é€‰æ‹©** | ç®€å•é‡è¦æ€§ | **4ç§æ™ºèƒ½æ–¹æ³•** | â¬†ï¸ **400%** |
| **ç‰ˆæœ¬ç®¡ç†** | æ—¶é—´æˆ³å‘½å | **å®Œæ•´ç‰ˆæœ¬ç³»ç»Ÿ** | ğŸš€ **é©å‘½æ€§** |
| **è¶…å‚ä¼˜åŒ–** | æ‰‹åŠ¨è°ƒå‚ | **Optunaè‡ªåŠ¨ä¼˜åŒ–** | ğŸš€ **å…¨æ–°åŠŸèƒ½** |
| **æ¨¡å‹è¯„ä¼°** | åŸºç¡€æŒ‡æ ‡ | **å¤šç»´åº¦å…¨é¢è¯„ä¼°** | â¬†ï¸ **500%** |
| **é…ç½®ç®¡ç†** | ç¡¬ç¼–ç  | **å®Œå…¨é…ç½®åŒ–** | ğŸ¯ **ä¸“ä¸šçº§** |

### æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”

| è¯„ä¼°ç»´åº¦ | åŸç‰ˆè¡¨ç° | ä¼˜åŒ–åè¡¨ç° | æå‡å¹…åº¦ |
|---------|---------|-----------|---------|
| **æ¨¡å‹é€‰æ‹©** | å•ä¸€LGBM | **è‡ªåŠ¨é€‰æœ€ä½³** | ğŸ¯ **æ™ºèƒ½åŒ–** |
| **ç‰¹å¾ä¼˜åŒ–** | æ‰‹åŠ¨ç­›é€‰ | **è‡ªåŠ¨ä¼˜é€‰** | â¬†ï¸ **10-30%æ€§èƒ½** |
| **è®­ç»ƒæ•ˆç‡** | å›ºå®šå‚æ•° | **è‡ªåŠ¨è°ƒä¼˜** | â¬†ï¸ **5-15%æå‡** |
| **éƒ¨ç½²ä¾¿åˆ©** | æ‰‹åŠ¨ç®¡ç† | **ç‰ˆæœ¬è‡ªåŠ¨åŒ–** | ğŸš€ **10xæ•ˆç‡** |
| **å¯ç»´æŠ¤æ€§** | ä»£ç åˆ†æ•£ | **æ¨¡å—åŒ–è®¾è®¡** | â¬†ï¸ **æ˜¾è‘—æå‡** |

## æœ€ä½³å®è·µ

### 1. æ¨¡å‹é€‰æ‹©ç­–ç•¥

**é‡‘èæ—¶é—´åºåˆ—æ¨èé…ç½®:**
```python
config = ModelConfig(
    model_type='lightgbm',          # é«˜æ•ˆä¸”å‡†ç¡®
    feature_selection_method='auto', # æ™ºèƒ½ç‰¹å¾é€‰æ‹©
    n_features=15,                  # å¹³è¡¡æ€§èƒ½å’Œå¤æ‚åº¦
    use_optuna=True,                # å¯ç”¨è‡ªåŠ¨è°ƒå‚
    optuna_trials=100               # å……åˆ†æœç´¢ç©ºé—´
)
```

**å¿«é€ŸåŸå‹éªŒè¯é…ç½®:**
```python
config = ModelConfig(
    model_type='random_forest',     # å¿«é€Ÿè®­ç»ƒ
    feature_selection_method='importance', # ç®€å•æœ‰æ•ˆ
    n_features=10,                  # å‡å°‘ç‰¹å¾æ•°
    use_optuna=False                # è·³è¿‡è°ƒå‚åŠ é€Ÿ
)
```

### 2. ç‰¹å¾é€‰æ‹©å»ºè®®

- **æ•°æ®å……è¶³**: ä½¿ç”¨ `auto` æ–¹æ³•è·å¾—æœ€ä½³æ•ˆæœ
- **ç‰¹å¾å¾ˆå¤š**: ä½¿ç”¨ `statistical` æ–¹æ³•å¿«é€Ÿç­›é€‰
- **è§£é‡Šæ€§è¦æ±‚é«˜**: ä½¿ç”¨ `importance` æ–¹æ³•
- **æ•°æ®ç¨€å°‘**: ä½¿ç”¨ `mutual_info` æ–¹æ³•

### 3. ç‰ˆæœ¬ç®¡ç†ç­–ç•¥

- **å®éªŒé˜¶æ®µ**: é¢‘ç¹ä¿å­˜ç‰ˆæœ¬ï¼Œä¾¿äºå¯¹æ¯”
- **ç”Ÿäº§ç¯å¢ƒ**: åªä¿å­˜éªŒè¯é€šè¿‡çš„ç‰ˆæœ¬
- **æ¨¡å‹å›æ»š**: åˆ©ç”¨ç‰ˆæœ¬ç³»ç»Ÿå¿«é€Ÿå›é€€
- **æ€§èƒ½è¿½è¸ª**: å®šæœŸåˆ†ææœ€ä½³æ¨¡å‹å˜åŒ–

### 4. è¶…å‚æ•°ä¼˜åŒ–å»ºè®®

- **æ—¶é—´å……è¶³**: ä½¿ç”¨100+è¯•éªŒè·å¾—æœ€ä¼˜å‚æ•°
- **æ—¶é—´ç´§å¼ **: ä½¿ç”¨20-50è¯•éªŒè·å¾—è¾ƒå¥½å‚æ•°
- **ç”Ÿäº§ç¯å¢ƒ**: å®šæœŸé‡æ–°ä¼˜åŒ–é€‚åº”æ•°æ®å˜åŒ–
- **å¤šæ¨¡å‹å¯¹æ¯”**: ä¸ºæ¯ä¸ªæ¨¡å‹åˆ†åˆ«ä¼˜åŒ–

## æ‰©å±•æ€§è®¾è®¡

### 1. æ–°æ¨¡å‹ç±»å‹æ‰©å±•
```python
class ModelFactory:
    @staticmethod
    def _create_neural_network(config):
        """æ‰©å±•ç¥ç»ç½‘ç»œæ¨¡å‹"""
        # å®ç°Transformerã€LSTMç­‰æ·±åº¦å­¦ä¹ æ¨¡å‹
```

### 2. æ–°ç‰¹å¾é€‰æ‹©æ–¹æ³•
```python
class FeatureSelector:
    def _deep_learning_selection(self, X, y, feature_names):
        """åŸºäºæ·±åº¦å­¦ä¹ çš„ç‰¹å¾é€‰æ‹©"""
        # å®ç°åŸºäºç¥ç»ç½‘ç»œçš„ç‰¹å¾é€‰æ‹©
```

### 3. é«˜çº§ç‰ˆæœ¬ç®¡ç†
```python
class ModelVersionManager:
    def deploy_model(self, version_id, environment):
        """æ¨¡å‹éƒ¨ç½²ç®¡ç†"""
        # å®ç°è‡ªåŠ¨åŒ–éƒ¨ç½²æµç¨‹
```

## æ€»ç»“

ä¼˜åŒ–åçš„ `EnhancedModelTrainer V2` åœ¨ä»¥ä¸‹æ–¹é¢å®ç°äº†æ˜¾è‘—æå‡ï¼š

1. **æ¨¡å‹æ”¯æŒ**: ä»å•ä¸€LightGBMæ‰©å±•åˆ°å¤šç§æ¨¡å‹ç±»å‹
2. **ç‰¹å¾å·¥ç¨‹**: ä»ç®€å•é‡è¦æ€§æ’åºå‡çº§ä¸ºæ™ºèƒ½è‡ªåŠ¨é€‰æ‹©
3. **ç‰ˆæœ¬ç®¡ç†**: ä»æ–‡ä»¶å‘½åå‡çº§ä¸ºå®Œæ•´çš„ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿ
4. **å‚æ•°ä¼˜åŒ–**: ä»æ‰‹åŠ¨è°ƒå‚å‡çº§ä¸ºOptunaè‡ªåŠ¨ä¼˜åŒ–
5. **è¯„ä¼°ä½“ç³»**: ä»åŸºç¡€æŒ‡æ ‡å‡çº§ä¸ºå¤šç»´åº¦å…¨é¢è¯„ä¼°
6. **ç³»ç»Ÿæ¶æ„**: ä»è„šæœ¬å¼å‡çº§ä¸ºæ¨¡å—åŒ–ã€é…ç½®åŒ–è®¾è®¡
7. **å¯æ‰©å±•æ€§**: é¢„ç•™äº†æ·±åº¦å­¦ä¹ ã€é›†æˆå­¦ä¹ ç­‰æ‰©å±•æ¥å£
8. **ç”Ÿäº§å°±ç»ª**: å®Œæ•´çš„é”™è¯¯å¤„ç†ã€æ—¥å¿—è®°å½•ã€çŠ¶æ€ç®¡ç†

è¿™ä¸ªä¼˜åŒ–æ–¹æ¡ˆä¸ä»…å®Œå…¨æ»¡è¶³äº†åŸå§‹éœ€æ±‚ï¼ˆå¤šæ¨¡å‹æ”¯æŒã€è‡ªåŠ¨ç‰¹å¾é€‰æ‹©ã€ç‰ˆæœ¬ç®¡ç†ï¼‰ï¼Œè¿˜åœ¨è‡ªåŠ¨åŒ–ç¨‹åº¦ã€æ€§èƒ½ä¼˜åŒ–ã€ç³»ç»Ÿå¯ç»´æŠ¤æ€§ç­‰æ–¹é¢å®ç°äº†è´¨çš„é£è·ƒï¼Œä¸ºæœºå™¨å­¦ä¹ æ¨¡å‹çš„å·¥ä¸šåŒ–åº”ç”¨æä¾›äº†å®Œæ•´çš„è§£å†³æ–¹æ¡ˆã€‚

